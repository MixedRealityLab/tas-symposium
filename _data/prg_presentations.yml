

workshops_am:
  - id: workshop_1
    type: workshop
    collapsable: true
    title: Trustworthy AI for Enhancing Decision-Making in Healthcare
    abstract: >
      As AI technology advances, its role in healthcare decision-making becomes increasingly prominent, necessitating a focus on trustworthiness and collaboration. This workshop on AI and Healthcare is dedicated to building community and exploring new partnerships and project opportunities in this important area. First, we will introduce the TAME Pain case study, showcasing how AI-driven solutions can improve pain management through successful collaborations in the UK and US, highlighting both the challenges faced and the impactful results achieved. Then, we will introduce the HEAD collaboration and its mission to foster interdisciplinary research and innovation in AI and healthcare. We will discuss three innovative projects that emerged from the recent summer residency program, detailing their objectives, methodologies, and potential impacts. Each presentation will include a feedback and discussion session, fostering engagement and insights into the future of AI in healthcare. This workshop will provide a platform for knowledge exchange and the formation of meaningful collaborations.
    website: https://sites.google.com/view/trustworthy-ai-in-healthcare/home

  - id: workshop_2
    type: workshop
    collapsable: true
    title: "Coming Together: Addressing Ethical AI with Diverse Teams and Perspectives"
    abstract: >
      It is important to understand what we are willing to entrust to AI as society integrates these systems into more facets of public, private, and commercial life. Trust is a key concept relating to autonomous systems as is outlined in AI Ethics guidelines, frameworks, and regulation. While there is universal agreement on the importance of trust and there are common key principles, there is no agreement on what defines trust and how to develop, design and deploy trustworthy systems. Furthermore, different disciplines approach trust in various ways. This workshop aims to facilitate interactive discussions on how to address issues of trustworthiness in autonomous AI systems through an interdisciplinary lens. Workshop participants will hear insights from guest speaker Dr. Steve Kramer, Chief Scientist at KUNGFU.AI, an Austin-based AI consulting firm providing interdisciplinary AI expertise. Following a presentation, participants will be encouraged to approach AI from a set of diverse lenses with the goal of reaching consensus on key ethical issues through a case study challenge. This event is designed to broadly appeal to researchers from various backgrounds (both technical and non-technical) working on or interested in issues at the intersection of AI and ethics.
    website: https://sites.google.com/view/coming-together/home

  - id: workshop_3
    type: workshop
    collapsable: true
    title: "Automating Telepresence and Computer-mediated Communication: Identifying Implications and Challenges"
    abstract: >
      The implementation of autonomous features in computer-mediated communication and telepresence technologies (from videoconferencing to VR and robotic telepresence) is a growing trend. Whilst automation in such technologies can offer many benefits -e.g., faster communication and reduced mental workload -, it can also reduce the users' agency over how they present themselves in social contexts. In this workshop, we will be identifying and discussing the ethical considerations, as well as implications relating to usability and accessibility, that automation introduces when used in systems for remote communication. This will be a half-day, hybrid workshop consisting of brainstorming and guided discussion activities, aiming to initiate a conversation regarding the multifaceted implications of automation in this field and set directions for future work. Please visit [our website](https://sites.google.com/view/tas24automatingtelepresence/home) for more information on the workshop and how you can participate!
    website: https://sites.google.com/view/tas24automatingtelepresence/home
 

workshops_pm:
  - id: workshop_4
    type: workshop
    collapsable: true
    title: "Human-AI Alignment: Developing a research agenda by bridging interdisciplinary approaches"
    abstract: >
      With the increased capability and proliferation of AI systems across various domains, ensuring that these systems align with human intentions and values is crucial. Research across disciplines, such as computer science, human-computer interaction, philosophy, and policy, usually targets one aspect of AI alignment, leading to a siloed understanding of its challenges. This workshop aims to foster a comprehensive understanding of human-AI alignment through the integration of diverse disciplinary perspectives.
    website: https://sites.google.com/utexas.edu/tas24human-aialignment/home

  - id: workshop_5
    type: workshop
    collapsable: true
    title: Responsible Internet Futures
    abstract: >
      <p>
      The Internet is of significant interest to research communities across academic disciplines and across the globe. Areas of current focus include digital divides, online privacy, online wellbeing, governance, censorship, and information propagation. It is essential our communities come together to consider how it might be possible to foster responsible Internet futures. This involves identifying the opportunities and challenges regarding a safe, equitable, accessible and useful Internet. It also requires taking a global perspective. 
      </p><p>
      In this half-day workshop we bring together interested researchers to suggest and debate visions for responsible Internet futures. We will combine invited speaker presentations with discussion sessions and we seek to co-create an initial pathway towards responsibility as part of these discussions. All TAS’24 Symposium attendees are welcome to join the workshop. 
      </p><p>
      Outline of the event:<br>
      <b>1.30pm</b>: Welcome and Introduction<br>
      <b>1.45pm</b>: Provocations. Four invited speakers will give their responses (10-15 mins each) to either or both of the following questions:<br>
      &nbsp; &nbsp; &nbsp;What could a responsible Internet look like?<br>
      &nbsp; &nbsp; &nbsp;What is a suitable pathway towards achieving a responsible Internet
      </p><p>
      The speakers are:<br>
      Robin Wilton, Director for Internet Trust, the Internet Society<br>
      Sharon Strover, Philip G. Warner Regents Professor in Communication, University of Texas at Austin<br>
      Thiago Guimaraes Moraes, PhD candidate at Universidade de Brasilia (UnB) and Vrije Universiteit Brussels, and Coordinator of Innovation and Research at the Brazilian Data Protection Authority<br>
      Jeremie Clos, Assistant Professor of Computer Science, University of Nottingham
      </p><p>
      <b>3.10pm</b>: Break
      </p><p>
      <b>3.30pm</b>: Small group discussions: what is possible for a responsible Internet, who needs to be involved, what are the obstacles, how might they be overcome?
      </p><p>
      <b>4.10pm</b>: Plenary discussion and next steps
      </p><p>
      <b>4.45pm</b>: Close
      </p><p>
      The workshop is being run as within the UKRI-funded Responsible AI UK project ‘TAS-Hub and Good Systems Strategic Collaboration’. Two further online workshops on Responsible Internet Futures are planned within the project for 2025. If interested, attendees at the TAS’24 workshop will be invited to attend these subsequent ones too
      </p><p>
      To find out more about the workshop, please contact <a href="mailto:helena.webb@nottingham.ac.uk">helena.webb@nottingham.ac.uk</a>.
      </p>

  - id: workshop_6
    type: workshop
    collapsable: true
    title: A Hands-on Workshop for Responsible Research and Innovation
    abstract: >
      Responsible Research and Innovation (RRI) is a continuous process to anticipate how research/innovation outcomes and processes may affect people and the environment in the future, and act in the present to gain the most benefit, minimise risks, and avoid harm. There remains a gap between the theory and practice of RRI. Through collaborative activities using Responsible Innovation Prompts and Practice Cards with case studies, attendees gain knowledge and hands-on experience in systematically identifying responsibility challenges, reflect, and make action plans to ensure inclusive practices, foster ethical and responsible decision-making, and embed RRI in projects.
    website: https://sites.google.com/view/tas24responsibleinnovation/

  - id: workshop_7
    type: workshop
    collapsable: true
    title: The regulation of workplaces in the age of collaborative robotics towards trustworthy embodied autonomous systems
    abstract: >
      <p>
      Since the first industrial revolution, workplaces have been a highly regulated and governed area of activity. From the early developments of health and safety law to development around working time, the relationship between humans, their employers and their fellow employees has been an important area of intervention. 
      </p><p>
      When static robots were introduced onto production lines, they were required to be guarded like any other tool. However, with the development of robotics and the embodiment of artificial intelligence in robots made to collaborate, the old models of regulation of robots are outdated. Human-robot collaboration has the potential to make a huge contribution to the future economic, enabling manufacturing process that bring together the best of both humans and robots. In order for this to be the future, we have to ensure that the appropriate regulatory framework is in place, to enable workers to both feel and be safe, and for businesses to have comfort in introducing collaborative robots into their workplaces.
      </p><p class="mb-0">
      This workshop aims to explore the challenges of regulating a workplace that uses (or wishes to use) collaborative robots. It seeks to identify the issues that require further research or would benefit from consideration by policy-makers.
      </p>
  website: https://sites.google.com/view/cobotlaw/home

session_1:
  - id: plenary_1
    type: plenary
    abstract: >
      <b>Dr. Kate Devlin</b> will give a keynote address about the purpose and legacy of the Trustworthy Autonomous System Program. Dr Devlin is a Reader in Artificial Intelligence & Society in the Department of Digital Humanities, King's College London. With an undergraduate degree in archaeology (Queens University Belfast) and an MSc (Queens University Belfast) and PhD (University of Bristol) in computer science, her research investigates how people interact with and react to technologies, both past and future. Kate is the author of the critically-acclaimed book Turned On: Science, Sex and Robots (Bloomsbury, 2018), which examines the ethical and social implications of technology and intimacy.

session_2:
  - id: paper_1
    title: "Negotiating Autonomy and Trust when Performing with an AI Musician"
    authors: Steve Benford, Marco Amerotti, Bob Sturm and Juan Martinez Avila
  - id: paper_2
    title: "Is Your Prompt Detailed Enough? Exploring the Effects of Prompt Coaching on Users’ Perceptions, Engagement, and Trust in Text-to-Image Generative AI Tools"
    authors: Cheng Chen, Sangwook Lee, Eunchae Jang and S.Shyam Sundar
  - id: paper_3
    title: "Fostering Trust Through User Interface Design in Multi-Drone Search and Rescue"
    authors: Johanna Ahlskog, Maria-Theresa Bahodi, Artur Lugmayr and Timothy Merritt
  - id: paper_4
    title: "Show Me What’s Wrong: Impact of Explicit Alerts on Novice Supervisors of a Multi-Robot Monitoring System"
    authors: Maria-Theresa Bahodi, Niels van Berkel, Mikael Skov and Timothy Merritt

session_3:
  groups:
    - title: Extended Abstract Posters
      presentations:
      - id: ea_poster_1
        title: "Design and Evaluation of a Tool to assist Small-Medium Organisations (SMOs) to implement Automated Decision-Making (ADM)."
        authors: Kathryn Baguley, Joel Fischer and Richard Hyde
      - id: ea_poster_2
        title: "An Interdependence Frame for (Semi) Autonomous Robots: The Case of Mobile Robotic Telepresence"
        authors: Andriana Boudouraki and Gisela Reyes-Cruz
      - id: ea_poster_3
        title: "Investigating the Impact of Generative AI on Students and Educators: Evidence and Insights from the Literature"
        authors: Jeremie Clos and Yoke Yie Chen
      - id: ea_poster_4
        title: "Designing and Evaluating a Discourse Analysis Dashboard"
        authors: Xin Yu Liew, Nazia Hameed, Jeremie Clos and Joel Fischer
      - id: ea_poster_5
        title: "Responsibility and Regulation: Exploring Social Measures of Trust in Medical AI"
        authors: Glenn McGarry, Andrew Crabtree, Alan Chamberlain and Lachlan D Urquhart
      - id: ea_poster_6
        title: "The Final 100 Meters: Touch and Joystick Controls for Guiding Autonomous Vehicles"
        authors: Timothy Merritt, Eleftherios Papachristos, Victor Barsted, Hogir Hiva Ibrahim Sabir and Peter Højer Holdensgaard
      - id: ea_poster_7
        title: "Sound Strategies for Safe Driving: Exploring Auditory Interventions to Counteract Passive Driver Fatigue"
        authors: Eleftherios Papachristos, Timothy Merritt, Eike Schneiders, David Jahanshiri, Alef Pir and Andrei Ciobanu
      - id: ea_poster_8
        title: "Responsibility Statement on research project outputs- to who and what for?"
        authors: Virginia Portillo, Helena Webb, Peter Craigon, Robin Wilton, Liz Dowthwaite and Ephraim Luwemba
      - id: ea_poster_9
        title: "Reimagining the Design of Mobile Robotic Telepresence: Reflections from a Hybrid Design Workshop"
        authors: Gisela Reyes-Cruz, Juan Martinez Avila, Eike Schneiders and Andriana Boudouraki
      - id: ea_poster_10
        title: "Meta-Meme: a Responsible Researcher's Tool for the analysis of Internet Memes"
        authors: Giovanni Schiazza, Helena Webb, Jeremie Clos, Patrick Brundell and Annemarie Walter
      - id: ea_poster_11
        title: "A Survey of Lay People's Willingness to Generate Legal Advice using Large Language Models (LLMs)"
        authors: Tina Seabrooke, Eike Schneiders, Liz Dowthwaite, Joshua Krook, Natalie Leesakul, Jeremie Clos, Horia Maior and Joel Fischer
      - id: ea_poster_12
        title: "Uneven Eyes: The Impact of Inconsistent Local Surveillance Policies on Public Trust"
        authors: Sharon Strover, Sheila Lalwani and Azza El-Masri
      - id: ea_poster_13
        title: "Responsible AI in policing"
        authors: Helena Webb, Nicholas Fitzroy-Dale, Saamiya Aqeel, Anna Maria Piskopani, Quentin Stafford-Fraser, Christos Nikolaou, Liz Dowthwaite, Derek McAuley and Christoper Hargreaves
      - id: ea_poster_14
        title: "Examining the Feasibility of AI-Generated Questions in Educational Settings"
        authors: Omar Zeghouani, Zawar Ali, William Simson van Dijkhuizen, Jia Wei Hong and Jeremie Clos

    - title: Non-Archival Posters
      presentations:
      - id: na_poster_1
        title: "A Facilitated Residential Approach: Coalescing Collaborative Research Projects for Health Equity in AI Decisions - HEAD Residency 2024"
        authors: Pepita Barnard
      - id: na_poster_2
        title: "Digital Placemaking and Co-Constitutive Evolution: The Role of Virtual Reality in How People Form a Sense of Place"
        authors: Takayuki Suzuki
      - id: na_poster_3
        title: "U-Trustworthy Models. Reliability, Competence, and Confidence in Decision-Making"
        authors: Ritwak Vashistha
      - id: na_poster_4
        title: "TAME Pain: Trustworthy AssessMEnt of Pain from Speech and Audio for the Empowerment of Patients"
        authors: Tu-Quyen Dao
      - id: na_poster_5
        title: "Utilising AI to measure the unmeasurable: Trust in a black-box solution to measure citizen science impact"
      - id: na_poster_6
        title: "Guiding Concepts for Responsible AI"
        authors: Minha Lee
      - id: na_poster_7
        title: "Health AI Platform for Decision Support toward Equitable Delivery of Healthcare to Multi-Factor Isolated Communities"
        authors: Matt Kammer-Kerwick

session_4:
  - id: paper_5
    title: "Human-Robot Interaction Experiment: Minor Changes; Significant Differences"
    authors: Zahra Rezaei Khavas and Paul Robinette 
  - id: paper_6
    title: "Swift Trust in Mobile Ad Hoc Human-Robot Teams"
    authors: Sanja Milivojevic, Mehdi Sobhani, Nicola Webb, Zachary Madin, James Ward, Sagir Yusuf, Chris Baber and Edmund Hunt
  - id: paper_7
    title: "Mapping Safe Zones for Co-located Human-UAV Interaction"
    authors: Ayodeji Abioye, Lisa Bidgood, Sarvapali Ramchurn and Mohammad Soorati
  - id: paper_8
    title: "Trust Transfer in Robots between Task Environments"
    authors: Theresa Law, Meia Chita-Tegmark and Matthias Scheutz

session_5:
  - id: paper_9
    title: "Ethical AI Regulatory Sandboxes: Insights from cyberspace regulation and Internet governance"
    authors: Thiago Moraes
  - id: paper_10
    title: "What’s missing from this picture? Ethical, legal, and practical challenges for autonomous-vehicle data-recorders"
    authors: Carolyn Ten Holter, Lars Kunze, Jo-Ann Pattinson, Pericle Salvini, Jonathan Attias and Marina Jirotka
  - id: paper_11
    title: "Not the Law's First Rodeo: Towards regulating trustworthy collaborative industrial embodied autonomous systems"
    authors: Natalie Leesakul, Jeremie Clos and Richard Hyde
  - id: paper_12
    title: "Trustworthy Airspaces of the Future: Hopes and concerns of experts regarding Uncrewed Traffic Management systems"
    authors: Harriet Cameron, Neil McBride, Paschal Ochang and Bernd C. Stahl

session_7:
  - id: paper_13
    title: "I can do anything with my AV data (but I won’t do that): Public attitudes towards data recorders in self-driving cars"
    authors: Jo-Ann Pattinson, Carolyn Ten Holter, Keri Grieman, Pericle Salvini, Lars Kunze and Marina Jirotka
  - id: paper_14
    title: "Encoding Social & Ethical Values in Autonomous Navigation: Philosophies Behind an Interactive Online Demonstration"
    authors: Yun Tang, Luke Moffat, Weisi Guo, Corinne May-Chahal, Joe Deville and Antonios Tsourdos
  - id: paper_15
    title: >
      "Trust equals less death - it's as simple as that" : Developing a Socio-technical Framework for Trustworthy Defence and Security Automated Systems"
    authors: Asieh Salehi Fathabadi and Pauline Leonard
  - id: paper_16
    title: "Brokerbot: A Cryptocurrency Chatbot in the Social-technical Gap of Trust"
    authors: Minha Lee, Lily Frank and Wijnand IJsselsteijn

session_8:
  - id: keynote_1
    type: keynote
    abstract: >
      This keynote talk will discuss psychological aspects of autonomous systems by drawing out the tension between machine agency and human agency, especially as they play out in the context of online media platforms. While automated features offer many conveniences, they also threaten our privacy, promote addictive use, and lead us down rabbit holes of extreme content, making us vulnerable to misinformation. If users are to avoid such negative consequences, they will need to be more deliberate and mindful in their interactions, which might detract from the very purpose of automation. This poses a design challenge, which could be addressed by making automation a technological affordance, and drawing upon concepts and mechanisms from the speaker’s model of Human-AI Interaction based on his Theory of Interactive Media Effects (HAII-TIME), as we attempt to build socially responsible trust in autonomous systems.
      <br><br>
      <i><b>S. Shyam Sundar</b> (PhD, Stanford University)  is Evan Pugh University Professor and James P. Jimirro Professor of Media Effects, co-director of the Media Effects Research Laboratory, and Director of the Center for Socially Responsible Artificial Intelligence at Penn State University. Prof. Sundar is a theorist as well as an experimentalist. His theoretical contributions include several original models on the social and psychological consequences of communication technology such as Modality-Agency-Interactivity-Navigability (MAIN) Model, and the Theory of Interactive Media Effects (TIME), along with its extension to Human-AI Interaction (HAII-TIME). His research examines social and psychological effects of interactive media, specifically the role played by technological affordances in shaping user experience of mediated communications. Current research pertains to psychological effects of Human-AI interaction in media contexts, ranging from personalization and recommendation to fake news and content moderation. His research portfolio includes extensive examination of user responses to online sources, including machine sources such as chatbots and smart speakers. His research is supported by National Science Foundation (NSF) and National Institutes of Health (NIH), among others. He is editor of the first-ever Handbook of the Psychology of Communication Technology (Blackwell Wiley, 2015). He served as editor-in-chief of the Journal of Computer-Mediated Communication, 2013-2017.</i>

session_9:
  - id: paper_17
    title: "A Taxonomy of Domestic Robot Failure Outcomes: Understanding the impact of failure on trustworthiness of domestic robots"
    authors: Harriet R. Cameron, Simon Castle-Green, Muhammad Chughtai, Liz Dowthwaite, Ayse Kucukyilmaz, Horia Maior, Victor Ngo, Eike Schneiders and Bernd C. Stahl
  - id: paper_18
    title: "A risk-based trust framework for assuring the humans in human-machine teaming"
    authors: Zena Assaad
  - id: paper_19
    title: "A Multimethod Analysis of US Perspectives towards Trustworthy Autonomous Systems"
    authors: Pepita Barnard, Andriana Boudouraki and Jeremie Clos
  - id: paper_20
    title: "Supporting Ethical Decision-Making for Lethal Autonomous Weapons"
    authors: Spencer Kohn, Marvin Cohen, Athena Johnson, Mikhail Terman, Gershon Weltman and Joseph Lyons

session_10:
  - id: plenary_2
    type: plenary
    collapsable: true
    abstract: <b>Maria De-Arteaga</b> is an Assistant Professor at the Information, Risk and Operation Management (IROM) Department at the University of Texas at Austin, where she is also a core faculty member in the Machine Learning Laboratory and an affiliated faculty of Good Systems. She holds a joint PhD in Machine Learning and Public Policy and a M.Sc. in Machine Learning, both from Carnegie Mellon University, and a. B.Sc. in Mathematics from Universidad Nacional de Colombia. Her research focuses on the risks and opportunities of using AI to support experts’ decisions in high-stakes settings, with a particular interest in algorithmic fairness and human-AI collaboration. As part of her work, she characterizes risks of bias and erosion of decision quality when relying on AI, and develops algorithms and sociotechnical systems to enable responsible human-AI complementarity. She currently serves in the Executive Committee of the ACM FAccT Conference.

session_11:
  - id: paper_21
    title: "Technology for Environmental Policy: Exploring Perceptions, Values, and Trust in a Citizen Carbon Budget App"
    authors: Liz Dowthwaite, Gisela Reyes-Cruz, Yang Lu, Justyna Lisinska, Peter Craigon, Anna-Maria Piskopani, Elnaz Shafipour, Sebastian Stein and Joel Fischer
  - id: paper_22
    title: "When to Explain? Exploring the Effects of Explanation Timing on User Perceptions and Trust in AI systems"
    authors: Cheng Chen, Mengqi Liao and S.Shyam Sundar 
  - id: paper_23
    title: "LOOM: a Privacy-Preserving Linguistic Observatory of Online Misinformation"
    authors: Jeremie Clos, Emma McClaughlin, Pepita Barnard, Tino Tom and Sudarshan Yajaman 
  - id: paper_24
    title: "Measurable Trust: The Key to Unlocking User Confidence in Black-Box AI"
    authors: Puntis Palazzolo, Bernd Stahl and Helena Webb 